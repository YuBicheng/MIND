{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Han/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from data import HierDataModule\n",
    "from data import infer_preprocess\n",
    "from ERDE import ERDE_sample\n",
    "from model import HierClassifier\n",
    "from transformers import AutoTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from collections import defaultdict, Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from model import HierClassifier\n",
    "from ERDE import ERDE_chunk\n",
    "import xml.dom.minidom\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注意\n",
    "version_55前后正态分布sigma不同需要切换 55后为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Han/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/opt/conda/envs/Han/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = HierClassifier.load_from_checkpoint(\n",
    "    # without time factor\"lightning_logs/version_20/checkpoints/epoch=5-step=732.ckpt\"\n",
    "    #with time factor\"lightning_logs/version_34/checkpoints/epoch=6-step=854.ckpt\"\n",
    "    #\"lightning_logs/version_41/checkpoints/epoch=2-step=366.ckpt\"\n",
    "    # basic Tanh\"lightning_logs/version_45/checkpoints/epoch=5-step=732.ckpt\"\n",
    "    #sigmoid\"lightning_logs/version_46/checkpoints/epoch=4-step=610.ckpt\"\n",
    "    #relu \"lightning_logs/version_47/checkpoints/epoch=4-step=610.ckpt\"\n",
    "    #basic factor\"lightning_logs/version_48/checkpoints/epoch=8-step=1098.ckpt\"\n",
    "    #basic factor + norm \"lightning_logs/version_51/checkpoints/epoch=4-step=610.ckpt\" #second-with bug\n",
    "    # \"lightning_logs/version_53/checkpoints/epoch=4-step=610.ckpt\"\n",
    "    # \"lightning_logs/version_55/checkpoints/epoch=3-step=488.ckpt\"\n",
    "    #\"lightning_logs/version_57/checkpoints/epoch=4-step=610.ckpt\"   #bug fixed\n",
    "    #\"lightning_logs/version_58/checkpoints/epoch=4-step=610.ckpt\"   #sota basic schedule\n",
    "    #\"lightning_logs/version_96/checkpoints/epoch=3-step=488.ckpt\"    #fusion\n",
    "    #\"lightning_logs/version_187/checkpoints/epoch=2-step=366.ckpt\"\n",
    "    #\"lightning_logs/version_190/checkpoints/epoch=6-step=854.ckpt\"\n",
    "    \"lightning_logs/version_200/checkpoints/epoch=4-step=610.ckpt\"\n",
    ")\n",
    "clf.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(clf.model_type)\n",
    "max_len = clf.hparams.max_len\n",
    "max_posts = 16\n",
    "clf.cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"miniLM_L6_embs.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train_posts = data[\"train_posts\"]\n",
    "train_mappings = data[\"train_mappings\"]\n",
    "train_tags = data[\"train_labels\"]\n",
    "train_embs = data[\"train_embs\"]\n",
    "train_timepoints = data[\"train_timepoints\"]\n",
    "test_posts = data[\"test_posts\"]\n",
    "test_mappings = data[\"test_mappings\"]\n",
    "test_tags = data[\"test_labels\"]\n",
    "test_embs = data[\"test_embs\"]\n",
    "test_timepoints = data[\"test_timepoints\"]\n",
    "test_analyze = data[\"test_analyzes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert = SentenceTransformer('/mnt/proj/paraphrase-MiniLM-L6-v2').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_texts = [\n",
    "    \"I feel depressed.\",\n",
    "    \"I am diagnosed with depression.\",\n",
    "    \"I am treating my depression.\"\n",
    "]\n",
    "questionaire_single = [\n",
    "    \"I feel sad.\",\n",
    "    \"I am discouraged about my future.\",\n",
    "    \"I always fail.\",\n",
    "    \"I don't get pleasure from things.\",\n",
    "    \"I feel quite guilty.\",\n",
    "    \"I expected to be punished.\",\n",
    "    \"I am disappointed in myself.\",\n",
    "    \"I always criticize myself for my faults.\",\n",
    "    \"I have thoughts of killing myself.\",\n",
    "    \"I always cry.\",\n",
    "    \"I am hard to stay still.\",\n",
    "    \"It's hard to get interested in things.\",\n",
    "    \"I have trouble making decisions.\",\n",
    "    \"I feel worthless.\",\n",
    "    \"I don't have energy to do things.\",\n",
    "    \"I have changes in my sleeping pattern.\",\n",
    "    \"I am always irritable.\",\n",
    "    \"I have changes in my appetite.\",\n",
    "    \"I feel hard to concentrate on things.\",\n",
    "    \"I am too tired to do things.\",\n",
    "    \"I have lost my interest in sex.\"\n",
    "]\n",
    "\n",
    "template_embeddings = sbert.encode(depression_texts+questionaire_single)\n",
    "template_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dim = 768\n",
    "assert time_dim%24==0,'time dim should be '\n",
    "hour_span = time_dim//24\n",
    "minutes_span = 60//hour_span\n",
    "half_time_dim = time_dim//2\n",
    "# Normal distribution\n",
    "sigma = 1\n",
    "#sigma = 0.03 # befor version_55\n",
    "x = np.arange(-time_dim/2, time_dim/2, 1)\n",
    "y = np.multiply(np.power(np.sqrt(2 * np.pi) * sigma, -1), np.exp(-np.power(x, 2) / 2 * sigma ** 2))\n",
    "norm = torch.from_numpy(y).to(torch.float32)/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_timeindexs(timepoints):\n",
    "    hour_index = timepoints[:,0]\n",
    "    time_index = hour_index\n",
    "    return time_index.long()\n",
    "def norm_emb(timepoints:torch.tensor)->torch.tensor:\n",
    "    #norm_x = torch.arange(-self.time_dim/2,self.time_dim/2,1)\n",
    "    #raise Exception(norm_x) #[-xxx,...,xxx-1]\n",
    "        \n",
    "    #index = hour * hour_span + minute//minutes_span\n",
    "    # raise Exception(\"shape,dtype\", timepoints.shape,timepoints.dtype) #('shape', (1131, 2)) int64\n",
    "    indexs = timepoints[:,0] * hour_span + torch.floor(timepoints[:,0] / minutes_span).to(torch.int)\n",
    "    indexs = indexs.to(torch.int)\n",
    "    #raise Exception(indexs.max(),indexs.min())\n",
    "    embs = torch.zeros(0,time_dim)\n",
    "    for index in indexs:\n",
    "        timeline = norm\n",
    "        if index<half_time_dim:\n",
    "            cut = half_time_dim-index\n",
    "            left = norm[:cut]\n",
    "            right = norm[cut:]\n",
    "            timeline = torch.cat((right,left),dim=0)\n",
    "        elif index> half_time_dim:\n",
    "            cut = index-half_time_dim\n",
    "            left = norm[:time_dim-cut]\n",
    "            right = norm[time_dim-cut:]\n",
    "            timeline = torch.cat((right,left),dim=0)\n",
    "        embs = torch.cat((embs,timeline.unsqueeze(0)),dim=0)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401/401 [41:53<00:00,  6.27s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pred_probas = []\n",
    "user_basis = []\n",
    "num_updates_users = []\n",
    "num_posts_users = []\n",
    "for mappings in tqdm(test_mappings, total=len(test_mappings)):\n",
    "    user_posts = [test_posts[i] for i in mappings[::-1]]\n",
    "    timepoints = [test_timepoints[i] for i in mappings]\n",
    "    analyzes = [test_analyze[i] for i in mappings]\n",
    "    #raise Exception(analyzes.shape)\n",
    "    timepoints_ = np.array(timepoints)\n",
    "    timepoints_ = torch.from_numpy(timepoints_)\n",
    "    timepoints_emb = norm_emb(timepoints_)\n",
    "    timeindexs = trans_timeindexs(timepoints_)\n",
    "    embs = torch.from_numpy(test_embs[mappings])\n",
    "    #raise Exception(timepoints_emb.shape,embs.shape)\n",
    "    pred_probas = []\n",
    "    posts_bank = []\n",
    "    analyze_bank = []\n",
    "    embedding_bank = None\n",
    "    scores_bank = []\n",
    "    basis_bank = []\n",
    "    num_updates = 0\n",
    "    for pid, new_post in enumerate(user_posts):\n",
    "        # new_post = \"\"\n",
    "        # new_emb = sbert.encode(new_post).reshape(1, -1)\n",
    "        new_emb = test_embs[mappings[pid]].reshape(1, -1)\n",
    "        new_scores = cosine_similarity(new_emb, template_embeddings)[0]\n",
    "        best_template_id = new_scores.argmax()\n",
    "        new_score = new_scores[best_template_id]\n",
    "        new_analyze = analyzes[pid]\n",
    "        # take all new posts before capacity is all used\n",
    "        tpemb_bank = timepoints_emb[:pid,:]\n",
    "        tpindex_bank = timeindexs[:pid]\n",
    "        textemb_bank = embs[:pid,:]\n",
    "        #print(pid)\n",
    "        if len(posts_bank) < max_posts:\n",
    "            posts_bank.insert(0, new_post)\n",
    "            scores_bank.insert(0, new_score)\n",
    "            basis_bank.insert(0, best_template_id)\n",
    "            analyze_bank.insert(0, new_analyze)\n",
    "            #print(analyze_bank,posts_bank)\n",
    "            batch = infer_preprocess(tokenizer, posts_bank, max_len, tpemb_bank, textemb_bank,tpindex_bank,analyze_bank)\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.cuda()\n",
    "            with torch.no_grad():\n",
    "                logits, attn_score,sc = clf([batch])\n",
    "            num_updates += 1\n",
    "            proba = torch.sigmoid(logits).detach().cpu().item()\n",
    "            pred_probas.append(proba)\n",
    "            continue\n",
    "        min_id = np.argmin(scores_bank)\n",
    "        if new_score >= scores_bank[min_id]:\n",
    "            del posts_bank[min_id]\n",
    "            del scores_bank[min_id]\n",
    "            del basis_bank[min_id]\n",
    "            del analyze_bank[min_id]\n",
    "            posts_bank.insert(0, new_post)\n",
    "            scores_bank.insert(0, new_score)\n",
    "            basis_bank.insert(0, best_template_id)\n",
    "            analyze_bank.insert(0, new_analyze)\n",
    "            # make prediction\n",
    "            batch = infer_preprocess(tokenizer, posts_bank, max_len, tpemb_bank, textemb_bank,tpindex_bank,analyze_bank)\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.cuda()\n",
    "            with torch.no_grad():\n",
    "                logits, attn_score,sc = clf([batch])\n",
    "            num_updates += 1\n",
    "            proba = torch.sigmoid(logits).detach().cpu().item()\n",
    "            pred_probas.append(proba)\n",
    "            # TODO stop if meet condition\n",
    "        else:\n",
    "            pred_probas.append(pred_probas[-1])\n",
    "            # do nothing, save time\n",
    "            pass\n",
    "    sample_pred_probas.append(pred_probas)\n",
    "    num_updates_users.append(num_updates)\n",
    "    num_posts_users.append(len(user_posts))\n",
    "    user_basis.append(basis_bank)\n",
    "len(sample_pred_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_updates_users = pd.Series(num_updates_users)\n",
    "num_posts_users = pd.Series(num_posts_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_user_posts</th>\n",
       "      <th>num_infers</th>\n",
       "      <th>infer_portion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>401.000000</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>401.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>589.453865</td>\n",
       "      <td>61.376559</td>\n",
       "      <td>0.325146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>589.965998</td>\n",
       "      <td>25.972973</td>\n",
       "      <td>0.299691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.080808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>330.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.191617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1074.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.506849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_user_posts  num_infers  infer_portion\n",
       "count      401.000000  401.000000     401.000000\n",
       "mean       589.453865   61.376559       0.325146\n",
       "std        589.965998   25.972973       0.299691\n",
       "min         10.000000   10.000000       0.036500\n",
       "25%         86.000000   39.000000       0.080808\n",
       "50%        330.000000   62.000000       0.191617\n",
       "75%       1074.000000   82.000000       0.506849\n",
       "max       2000.000000  124.000000       1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"num_user_posts\": num_posts_users.describe(),\n",
    "    \"num_infers\": num_updates_users.describe(),\n",
    "    \"infer_portion\": (num_updates_users / num_posts_users).describe()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10412444843064504"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# portion of actual model inferences\n",
    "(num_updates_users.sum() / num_posts_users.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08624549975747224 0.06759191783539566\n"
     ]
    }
   ],
   "source": [
    "ERDE5 = ERDE_sample(sample_pred_probas, test_tags, threshold=0.5, o=5)\n",
    "ERDE50 = ERDE_sample(sample_pred_probas, test_tags, threshold=0.5, o=50)\n",
    "print(ERDE5, ERDE50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "deb5c85a0d181f020663b0781bb785da64b0ac73c1b94407b759932d81dbf297"
  },
  "kernelspec": {
   "display_name": "Han",
   "language": "python",
   "name": "han"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
